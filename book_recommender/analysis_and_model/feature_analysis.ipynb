{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis: How to fill missing ratings\n",
    "\n",
    "What is the probability that a user liked a book, given that they read another book by the author?\n",
    "\n",
    "Is there a strong relationship between genre and how highly a user rates a book?\n",
    "\n",
    "Is there a strong relationship between author and how highly a user rates a book?\n",
    "\n",
    "Does the rating a user gives a book change over time? Do people become less likely to rate books highly if they have been reviewing books for a longer time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8j/jqvkfjr12ns3lzbxz2m8scx00000gp/T/ipykernel_25164/1960509243.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reads = pd.read_csv('data/reads_cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "# loading in read books\n",
    "reads = pd.read_csv('data/reads_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'author', 'num ratings', 'rating',\n",
       "       '# times read', 'date read', 'date added', 'link', 'user_id',\n",
       "       'global_pop', 'book_id', 'book_tag', 'is_rated', 'average_user_rating',\n",
       "       'book_popularity_rated', 'book_popularity_read', 'user_books_rated',\n",
       "       'user_books_read', 'user_rating_variability', 'user_rating_percentage',\n",
       "       'book_rating_percentage', 'adjusted_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads['date read'] = list(map(lambda x: re.sub(\"not set\", \"\", x), reads['date read']))\n",
    "\n",
    "reads['date read'] = reads['date read'].apply(lambda x: x[:12] if ',' in x else x[:8])\n",
    "reads['date read'] = reads['date read'].apply(lambda x: x[:12] if ',' in x else x[:8])\n",
    "reads['date read'].head(20)\n",
    "\n",
    "reads['date read'] = pd.to_datetime(reads['date read'], format='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the probability that a user liked a book, given that they read a subsequent book by the author?\n",
    "\n",
    "To answer this question, we need to analyze cases where user's rated two books by the same author in cases where the date of reading is intact.\n",
    "\n",
    "For the purposes of this exercise, a person liked a book if the rating they gave the book is higher than their average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reads = reads.dropna(subset=['date read'])\n",
    "\n",
    "# adding 'liked book' variable\n",
    "reads['liked_book']  = reads['rating'] > reads['average_user_rating']\n",
    "\n",
    "# getting first book read by the author\n",
    "reads['first_book_by_author'] = reads.sort_values('date read').groupby(['user_id', 'author'])['book_tag'].transform('first')\n",
    "\n",
    "# getting number of books read by author\n",
    "reads['num_books_read_by_author'] = reads.sort_values('date read').groupby(['user_id', 'author'])['book_tag'].transform('nunique')\n",
    "\n",
    "# repeatedly read author\n",
    "reads['repeat_author'] = reads['num_books_read_by_author'] > 1\n",
    "\n",
    "# creating a df of each user's first read per author\n",
    "# excluding cases where they did not rate the first book\n",
    "first_books_rated = reads[(reads['book_tag'] == reads['first_book_by_author']) & (reads['rating'] > 0)].drop_duplicates(['user_id', 'author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given that a user read a second book by the author, there is a 63.61% chance they liked the first book.\n",
      "Given that a user did not read a second a book by the author, there is a 49.19% chance they liked the first book.\n",
      "The overall chance that a user liked the first book they read by an author is 52.31%.\n",
      "The number of times a user rated a book then read at least one more book by the same author was: 82135\n",
      "The number of times a user rated a book then did not read a second book by the author was : 297506\n"
     ]
    }
   ],
   "source": [
    "# summing \n",
    "liked_book_and_read_more = first_books_rated.loc[first_books_rated['repeat_author'], 'liked_book'].sum()\n",
    "liked_book_didnt_read_more = first_books_rated.loc[(first_books_rated['num_books_read_by_author'] <= 1), 'liked_book'].sum()\n",
    "\n",
    "reads['num_books_read_by_author'].describe()\n",
    "\n",
    "# sample size for each group\n",
    "n_read_more = first_books_rated.loc[(first_books_rated['num_books_read_by_author'] > 1), 'book_tag'].count()\n",
    "n_didnt_read_more = first_books_rated.loc[(first_books_rated['num_books_read_by_author'] <= 1), 'book_tag'].count()\n",
    "\n",
    "p_liked_read_more = liked_book_and_read_more / n_read_more\n",
    "\n",
    "p_liked_didnt_read_more = liked_book_didnt_read_more / n_didnt_read_more\n",
    "\n",
    "prob_liked = (liked_book_and_read_more + liked_book_didnt_read_more) / (n_didnt_read_more + n_read_more)\n",
    "\n",
    "print(f'Given that a user read a second book by the author, there is a {round(p_liked_read_more * 100, 2)}% chance they liked the first book.')\n",
    "print(f'Given that a user did not read a second a book by the author, there is a {round(p_liked_didnt_read_more * 100, 2)}% chance they liked the first book.')\n",
    "print(f'The overall chance that a user liked the first book they read by an author is {round(prob_liked * 100, 2)}%.')\n",
    "print(f'The number of times a user rated a book then read at least one more book by the same author was: {n_read_more}')\n",
    "print(f'The number of times a user rated a book then did not read a second book by the author was : {n_didnt_read_more}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the probability that a user likes a book is different, depending on whether or not they read a second book. To test whether or not this is a meaningful effect, we can use a generalized linear mixed model. \n",
    "\n",
    "Note: a traditional parametric test for differences in proportions is not appropriate here because we cannot assume independence between observations since books and users are repeated throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting booleans to 0/1\n",
    "first_books_rated['liked_book'] = first_books_rated['liked_book'].astype(int)\n",
    "first_books_rated['repeat_author'] = first_books_rated['repeat_author'].astype(int)\n",
    "\n",
    "# converting user_id and book_id to factors\n",
    "first_books_rated['user_id'] = pd.Categorical(first_books_rated['user_id']).codes\n",
    "first_books_rated['book_tag'] = pd.Categorical(first_books_rated['book_tag']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Proportion Difference: 0.1577, p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# Compute proportions for each Z level\n",
    "proportions = first_books_rated.groupby(['user_id', 'repeat_author'])['liked_book'].mean().unstack()\n",
    "counts = first_books_rated.groupby(['user_id', 'repeat_author'])['liked_book'].count().unstack()\n",
    "\n",
    "# Weighted difference of proportions\n",
    "prop_diff = (proportions[1] - proportions[0])\n",
    "weights = counts.sum(axis=1) / counts.sum().sum()  # Weight by stratum size\n",
    "weighted_diff = np.sum(prop_diff * weights)\n",
    "\n",
    "# Compute standard error\n",
    "se = np.sqrt(np.sum(weights**2 * (proportions[1] * (1 - proportions[1]) / counts[1] +\n",
    "                                  proportions[0] * (1 - proportions[0]) / counts[0])))\n",
    "\n",
    "# Compute z-score and p-value\n",
    "z_score = weighted_diff / se\n",
    "p_value = 2 * (1 - chi2.cdf(z_score**2, df=1))\n",
    "\n",
    "print(f\"Weighted Proportion Difference: {weighted_diff:.4f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
